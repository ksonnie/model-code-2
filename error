import pandas as pd
import numpy as np
from sklearn.model_selection import train_test_split
from sklearn.linear_model import LinearRegression, ElasticNet
from sklearn.ensemble import GradientBoostingRegressor
from sklearn.tree import DecisionTreeRegressor
from xgboost import XGBRegressor

# File path and relevant BSO sheets
file_path = "/Volumes/navy-fip4-ya-dev/data_cleansing_dev/visualization_dev/All BSOs Dashboards.xlsx"
bso_sheets = {
   'USFFC': 'FFC Proj',
   'RESFOR': 'RESFOR Proj',
   'PACFLT': 'PACFLT Proj'
}

# The all_results DataFrame is assumed to already exist in the script
# Example structure for reference:
# all_results = pd.DataFrame({
#     'BSO': [...],
#     'KPI Column': [...],
#     'Best Model': [...],
#     'Fit Analysis': [...],
# })

# Function to replace NA with zeros
def replace_na_with_zeros(df):
   return df.fillna(0)

# Function to process each BSO sheet and make predictions
def process_bso_sheets(file_path, bso_sheets, all_results):
   predictions_by_bso = {}
   
   for bso, sheet_name in bso_sheets.items():
       print(f"Processing BSO: {bso}, Sheet: {sheet_name}")
       
       # Read the sheet
       data = pd.read_excel(file_path, sheet_name=sheet_name)
       data['Date'] = pd.to_datetime(data['Date'], errors='coerce')
       
       # Check for invalid dates
       if data['Date'].isnull().any():
           print(f"Invalid dates found in sheet: {sheet_name}. Replacing with earliest valid date.")
           earliest_date = data['Date'].min()
           data['Date'].fillna(earliest_date, inplace=True)
       
       last_date = data['Date'].max()
       print(f"Last Date in {sheet_name}: {last_date}")
       
       future_dates = [last_date + pd.Timedelta(weeks=i) for i in range(1, 4)]
       print(f"Future Dates: {future_dates}")
       
       for kpi_column in data.columns:
           if kpi_column in ['Date', 'BSO']:
               continue  # Skip non-KPI columns
           
           model_row = all_results[
               (all_results['BSO'] == bso) &
               (all_results['KPI Column'] == kpi_column) &
               (all_results['Fit Analysis'] == 'Good Fit')
           ]
           
           if model_row.empty:
               print(f"No valid model found for KPI: {kpi_column} in BSO: {bso}. Skipping.")
               continue
           
           best_model_name = model_row.iloc[0]['Best Model']
           print(f"Using Model: {best_model_name} for KPI: {kpi_column}, BSO: {bso}")
           
           X = data[['Date']].copy()
           X['WeekOfYear'] = X['Date'].dt.isocalendar().week
           X['Year'] = X['Date'].dt.year
           X['DateNumeric'] = X['Date'].map(pd.Timestamp.toordinal)
           
           y = data[kpi_column].values
           print(f"Target Values (y) for {kpi_column}, {bso}: {y}")
           
           # Train the model
           if best_model_name == 'XGBoost Regressor':
               model = XGBRegressor(random_state=42)
           elif best_model_name == 'Gradient Boosting':
               model = GradientBoostingRegressor(random_state=42)
           elif best_model_name == 'Decision Tree':
               model = DecisionTreeRegressor(random_state=42)
           elif best_model_name == 'Linear Regression':
               model = LinearRegression()
           elif best_model_name == 'ElasticNet(alpha=0.1)':
               model = ElasticNet(alpha=0.1, random_state=42)
           else:
               print(f"Unknown Model: {best_model_name} for {kpi_column}. Skipping.")
               continue
           
           X_train, X_test, y_train, y_test = train_test_split(
               X[['DateNumeric', 'WeekOfYear', 'Year']], y, test_size=0.2, random_state=42)
           
           model.fit(X_train, y_train)
           print(f"Model trained successfully for KPI: {kpi_column}, BSO: {bso}")
           
           future_features = pd.DataFrame({'Date': future_dates})
           future_features['WeekOfYear'] = future_features['Date'].dt.isocalendar().week
           future_features['Year'] = future_features['Date'].dt.year
           future_features['DateNumeric'] = future_features['Date'].map(pd.Timestamp.toordinal)
           
           print(f"Future Features: {future_features}")
           
           future_predictions = model.predict(future_features[['DateNumeric', 'WeekOfYear', 'Year']])
           print(f"Predictions: {future_predictions}")
           
           for date, prediction in zip(future_dates, future_predictions):
               data = data.append({'Date': date, kpi_column: prediction}, ignore_index=True)
       
       predictions_by_bso[bso] = data
       print(f"Completed processing for BSO: {bso}")
   
   return predictions_by_bso


# Main section to process all BSO sheets
updated_bso_data = process_bso_sheets(file_path, bso_sheets, all_results)

# Access updated data for each BSO
for bso, updated_data in updated_bso_data.items():
   print(f"Updated DataFrame for {bso}:\n", updated_data.head())
