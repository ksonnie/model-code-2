import pandas as pd
import numpy as np
from sklearn.model_selection import train_test_split
from sklearn.linear_model import LinearRegression, ElasticNet
from sklearn.ensemble import GradientBoostingRegressor
from sklearn.tree import DecisionTreeRegressor
from xgboost import XGBRegressor

# File path and relevant BSO sheets
file_path = "/Volumes/navy-fip4-ya-dev/data_cleansing_dev/visualization_dev/All BSOs Dashboards.xlsx"
bso_sheets = {
   'USFFC': 'FFC Proj',
   'RESFOR': 'RESFOR Proj',
   'PACFLT': 'PACFLT Proj'
}

# The all_results DataFrame is assumed to already exist in the script
# Example structure for reference:
# all_results = pd.DataFrame({
#     'BSO': [...],
#     'KPI Column': [...],
#     'Best Model': [...],
#     'Fit Analysis': [...],
# })

# Function to replace NA with zeros
def replace_na_with_zeros(df):
   return df.fillna(0)

# Function to process each BSO sheet and make predictions
def process_bso_sheets(file_path, bso_sheets, all_results):
    predictions_by_bso = {}
    
    for bso, sheet_name in bso_sheets.items():
        print(f"Processing BSO: {bso}, Sheet: {sheet_name}")
        
        # Read the sheet
        data = pd.read_excel(file_path, sheet_name=sheet_name)
        data['Date'] = pd.to_datetime(data['Date'], errors='coerce')
        
        # Handle invalid dates
        if data['Date'].isnull().any():
            print(f"Invalid dates found in sheet: {sheet_name}. Replacing with earliest valid date.")
            earliest_date = data['Date'].dropna().min()
            data['Date'].fillna(earliest_date, inplace=True)
        
        last_date = data['Date'].max()
        print(f"Last Date in {sheet_name}: {last_date}")
        
        future_dates = [last_date + pd.Timedelta(weeks=i) for i in range(1, 4)]
        print(f"Future Dates: {future_dates}")
        
        for kpi_column in data.columns:
            if kpi_column in ['Date', 'BSO']:
                continue  # Skip non-KPI columns
            
            model_row = all_results[
                (all_results['BSO'] == bso) &
                (all_results['KPI Column'] == kpi_column) &
                (all_results['Fit Analysis'] == 'Good Fit')
            ]
            
            if model_row.empty:
                print(f"No valid model found for KPI: {kpi_column} in BSO: {bso}. Skipping.")
                continue
            
            best_model_name = model_row.iloc[0]['Best Model']
            print(f"Using Model: {best_model_name} for KPI: {kpi_column}, BSO: {bso}")
            
            X = data[['Date']].copy()
            X['WeekOfYear'] = X['Date'].dt.isocalendar().week
            X['Year'] = X['Date'].dt.year
            X['DateNumeric'] = X['Date'].map(pd.Timestamp.toordinal)
            
            y = data[kpi_column].values
            print(f"Target Values (y) for {kpi_column}, {bso}: {y}")
            
            # Validate `y` values
            if np.any(np.isnan(y)) or np.any(np.isinf(y)) or np.any(y > 1e6):
                print(f"Invalid target values found in KPI column {kpi_column} for BSO {bso}. Skipping...")
                continue
            
            # Train the model
            if best_model_name == 'XGBoost Regressor':
                model = XGBRegressor(random_state=42)
            elif best_model_name == 'Gradient Boosting':
                model = GradientBoostingRegressor(random_state=42)
            elif best_model_name == 'Decision Tree':
                model = DecisionTreeRegressor(random_state=42)
            elif best_model_name == 'Linear Regression':
                model = LinearRegression()
            elif best_model_name == 'ElasticNet(alpha=0.1)':
                model = ElasticNet(alpha=0.1, random_state=42)
            else:
                print(f"Unknown Model: {best_model_name} for {kpi_column}. Skipping.")
                continue
            
            X_train, X_test, y_train, y_test = train_test_split(
                X[['DateNumeric', 'WeekOfYear', 'Year']], y, test_size=0.2, random_state=42)
            
            model.fit(X_train, y_train)
            print(f"Model trained successfully for KPI: {kpi_column}, BSO: {bso}")
            
            # Prepare future features
            future_features = pd.DataFrame({'Date': future_dates})
            future_features['WeekOfYear'] = future_features['Date'].dt.isocalendar().week
            future_features['Year'] = future_features['Date'].dt.year
            future_features['DateNumeric'] = future_features['Date'].map(pd.Timestamp.toordinal)
            
            print(f"Future Features: {future_features}")
            
            future_predictions = model.predict(future_features[['DateNumeric', 'WeekOfYear', 'Year']])
            print(f"Predictions: {future_predictions}")
            
            # Add predictions to the data
            new_rows = pd.DataFrame({'Date': future_dates, kpi_column: future_predictions})
            data = pd.concat([data, new_rows], ignore_index=True)
        
        predictions_by_bso[bso] = data
        print(f"Completed processing for BSO: {bso}")
    
    return predictions_by_bso

# Collect results in a consolidated DataFrame
def consolidate_results(predictions_by_bso):
    consolidated_data = []
    for bso, data in predictions_by_bso.items():
        data['BSO'] = bso  # Add a BSO column to the DataFrame
        consolidated_data.append(data)
    # Combine all data into a single DataFrame
    consolidated_df = pd.concat(consolidated_data, ignore_index=True)
    return consolidated_df

# Main section to process and display results
updated_bso_data = process_bso_sheets(file_path, bso_sheets, all_results)

# Consolidate all results into a single DataFrame
consolidated_results = consolidate_results(updated_bso_data)




