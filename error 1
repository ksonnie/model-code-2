import pandas as pd
from sklearn.tree import DecisionTreeRegressor
from sklearn.preprocessing import MinMaxScaler
import numpy as np

# File path and relevant sheet name
file_path = "/Volumes/navy-fip4-ya-dev/data_cleansing_dev/visualization_dev/All BSOs Dashboards.xlsx"
sheet_name = "FFC Proj"

# List of KPI columns to process
kpi_columns = [
    "NULOs that Remain High Priority",
    "Billing exceeds Authorization (Abnormal Unfilled Customer Orders)",
    "RBC Level- Total Negative Billed",
    "RBC Level- Total Negative Authorizations",
]

# Load the Excel data
def load_data(file_path, sheet_name):
    data = pd.read_excel(file_path, sheet_name=sheet_name)
    data['Date'] = pd.to_datetime(data['Date'], errors='coerce')
    data.dropna(subset=['Date'], inplace=True)  # Drop rows with invalid dates
    return data

# Function to process all KPI columns and add predictions for each date
def process_kpi_columns(data, kpi_columns):
    scaler = MinMaxScaler()
    last_date = data['Date'].max()  # Get the latest date in the data

    # Prepare a DataFrame to hold the original and predicted data
    final_data = data.copy()

    for kpi_column in kpi_columns:
        if kpi_column in data.columns:
            print(f"Processing KPI: {kpi_column}")

            # Prepare historical data for the current KPI
            kpi_data = data[['Date', kpi_column]].copy()
            kpi_data.dropna(subset=[kpi_column], inplace=True)  # Remove rows where KPI is NaN

            # Skip processing if insufficient data
            if len(kpi_data) < 2:
                print(f"Skipping {kpi_column}: insufficient data.")
                continue

            # Convert Date to numeric for modeling
            kpi_data['DateNumeric'] = kpi_data['Date'].map(pd.Timestamp.toordinal)
            X = kpi_data[['DateNumeric']]
            y = kpi_data[kpi_column]

            # Scale the numeric data
            X_scaled = scaler.fit_transform(X)

            # Initialize and train the Decision Tree model
            model = DecisionTreeRegressor(random_state=42)
            model.fit(X_scaled, y)

            # Generate predictions for the next 3 weeks
            future_predictions = []
            current_last_date = last_date

            for i in range(3):
                # Prepare input for prediction
                next_date_numeric = scaler.transform([[current_last_date.toordinal()]])[0][0]
                next_prediction = model.predict([[next_date_numeric]])[0]

                # Append prediction
                future_predictions.append({'Date': current_last_date + pd.Timedelta(days=7), kpi_column: next_prediction})

                # Update historical data with the predicted value
                new_row = {
                    'Date': current_last_date + pd.Timedelta(days=7),
                    'DateNumeric': (current_last_date + pd.Timedelta(days=7)).toordinal(),
                    kpi_column: next_prediction
                }
                kpi_data = pd.concat([kpi_data, pd.DataFrame([new_row])], ignore_index=True)

                # Retrain the model with updated data
                X = kpi_data[['DateNumeric']]
                y = kpi_data[kpi_column]
                X_scaled = scaler.fit_transform(X)
                model.fit(X_scaled, y)

                # Update the date for the next iteration
                current_last_date += pd.Timedelta(days=7)

            # Add predictions to the final data
            future_predictions_df = pd.DataFrame(future_predictions)
            final_data = pd.merge(final_data, future_predictions_df, on="Date", how="outer")

    # Ensure the Date column is formatted correctly
    final_data['Date'] = pd.to_datetime(final_data['Date']).dt.strftime('%m/%d/%Y')
    return final_data

# Main execution
data = load_data(file_path, sheet_name)
final_data = process_kpi_columns(data, kpi_columns)
print(final_data)
