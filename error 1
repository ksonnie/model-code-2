import pandas as pd
import numpy as np
from sklearn.linear_model import LinearRegression
from sklearn.tree import DecisionTreeRegressor
from sklearn.ensemble import RandomForestRegressor
from xgboost import XGBRegressor
from sklearn.preprocessing import MinMaxScaler

# File path and sheet names
file_path = "/Volumes/navy-fip4-ya-dev/data_cleansing_dev/visualization_dev/All BSOs Dashboards.xlsx"

bso_sheets = {
    "USFFC": "FFC Proj",
    "RESFOR": "RESFOR Proj",
    "PACFLT": "PACFLT Proj"
}

# Prediction details based on R-squared table
prediction_details = [
    {"BSO": "USFFC", "KPI": "NULOs that Remain High Priority", "Model": "Random Forest"},
    {"BSO": "USFFC", "KPI": "Billing exceeds Authorization (Abnormal Unfilled Customer Orders)", "Model": "Decision Tree"},
    # Add all rows from the R-squared table
]

# Function to load data
def load_data(file_path, sheet_name):
    data = pd.read_excel(file_path, sheet_name=sheet_name)
    data['Date'] = pd.to_datetime(data['Date'], errors='coerce')
    data.dropna(subset=['Date'], inplace=True)
    return data

# Function to process and predict for each KPI
def process_kpi_predictions(data, kpi, model_name):
    scaler = MinMaxScaler()
    last_date = data['Date'].max()
    kpi_data = data[['Date', kpi]].dropna()

    if kpi_data.empty:
        print(f"No data available for KPI: {kpi}")
        return None

    kpi_data['DateNumeric'] = kpi_data['Date'].map(pd.Timestamp.toordinal)
    X = kpi_data[['DateNumeric']]
    y = kpi_data[kpi]
    X_scaled = scaler.fit_transform(X)

    # Initialize the model
    if model_name == "Linear Regression":
        model = LinearRegression()
    elif model_name == "Decision Tree":
        model = DecisionTreeRegressor(random_state=42)
    elif model_name == "Random Forest":
        model = RandomForestRegressor(random_state=42)
    elif model_name == "XGBoost":
        model = XGBRegressor(random_state=42)
    else:
        print(f"Unknown model: {model_name}")
        return None

    # Train the model
    model.fit(X_scaled, y)

    # Generate predictions for the next 3 weeks
    predictions = []
    for i in range(1, 4):
        next_date = last_date + pd.Timedelta(days=7 * i)
        next_date_numeric = scaler.transform([[next_date.toordinal()]])[0][0]
        prediction = model.predict([[next_date_numeric]])[0]
        predictions.append({'Date': next_date, kpi: prediction})

        # Update the historical data with the new prediction
        kpi_data = pd.concat([
            kpi_data,
            pd.DataFrame({'Date': [next_date], 'DateNumeric': [next_date.toordinal()], kpi: [prediction]})
        ])
        X = kpi_data[['DateNumeric']]
        y = kpi_data[kpi]
        X_scaled = scaler.fit_transform(X)
        model.fit(X_scaled, y)

    return predictions

# Main execution
final_results = {}
for bso, sheet_name in bso_sheets.items():
    print(f"Processing BSO: {bso}")
    data = load_data(file_path, sheet_name)

    bso_predictions = []
    for detail in prediction_details:
        if detail['BSO'] == bso and detail['KPI'] in data.columns:
            print(f"Processing KPI: {detail['KPI']} with model {detail['Model']}")
            kpi_predictions = process_kpi_predictions(data, detail['KPI'], detail['Model'])
            if kpi_predictions:
                bso_predictions.extend(kpi_predictions)

    # Convert to DataFrame
    bso_predictions_df = pd.DataFrame(bso_predictions)
    bso_predictions_df['BSO'] = bso
    final_results[bso] = bso_predictions_df

# Combine results for all BSOs
combined_results = pd.concat(final_results.values(), ignore_index=True)
combined_results['Date'] = combined_results['Date'].dt.strftime('%m/%d/%Y')  # Format the Date column

# Display final results
print(combined_results)
