import pandas as pd
from pyspark.sql import SparkSession
from pyspark.sql import functions as F
from pyspark.sql.types import IntegerType
from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor
from sklearn.tree import DecisionTreeRegressor
from sklearn.linear_model import LinearRegression
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import PowerTransformer
import numpy as np

# Initialize Spark session
spark = SparkSession.builder.appName("Per Model Prediction").getOrCreate()

# Define the KPI columns for each model
model_kpi_mapping = {
    'RandomForestRegressor': [
        'NULOs that Remain High Priority',
        'Billing exceeds Authorization (Abnormal Unfilled Customer Orders)'
    ],
    'GradientBoostingRegressor': [
        'RBC Level- Total Negative Authorizations',
        'Negative Liquidations - Travel (DTC: CS, CT, TO)'
    ],
    'DecisionTreeRegressor': [
        'RBC Level- Total Negative Billed',
        'Cost Transfer Allocation - "COE"'
    ],
    'LinearRegression': [
        'Permanent Journal Vouchers',
        'Invalid LOA'
    ]
}

# Load data
def load_data(sheet_name, bso_name):
    data = pd.read_excel("/Volumes/navy-fip4-ya-dev/data_cleansing_dev/visualization_dev/All BSOs Dashboards.xlsx", sheet_name=sheet_name)
    data['BSO'] = bso_name  # Add the BSO column
    return data

# Prediction logic
def generate_predictions(data, kpi_columns, model):
    predictions = []
    data['Date'] = pd.to_datetime(data['Date'])
    data['DateNumeric'] = data['Date'].map(pd.Timestamp.toordinal)  # Convert Date to numeric
    
    for kpi_column in kpi_columns:
        if kpi_column not in data.columns:
            print(f"KPI column {kpi_column} not found. Skipping...")
            continue

        X = data[['DateNumeric']]
        y = data[kpi_column].values

        # Apply transformation
        transformer = PowerTransformer()
        y_transformed = transformer.fit_transform(y.reshape(-1, 1)).flatten()

        # Train-test split
        X_train, X_test, y_train, y_test = train_test_split(X, y_transformed, test_size=0.2, random_state=42)
        
        # Fit the model
        model.fit(X_train, y_train)
        
        # Generate future dates
        last_date = data['Date'].max()
        future_dates = [last_date + pd.Timedelta(weeks=i) for i in range(1, 4)]
        future_numeric = pd.DataFrame({'DateNumeric': [d.toordinal() for d in future_dates]})

        # Make predictions
        future_preds = model.predict(future_numeric)
        future_preds_original = transformer.inverse_transform(future_preds.reshape(-1, 1)).flatten()

        # Store predictions
        for date, pred in zip(future_dates, future_preds_original):
            predictions.append({'Date': date, 'KPI': kpi_column, 'Prediction': pred, 'BSO': data['BSO'].iloc[0]})

    return predictions

# Run predictions for each model
def run_model_predictions(sheet_name, bso_name, model_name, kpi_columns):
    data = load_data(sheet_name, bso_name)
    model_map = {
        'RandomForestRegressor': RandomForestRegressor(random_state=42),
        'GradientBoostingRegressor': GradientBoostingRegressor(random_state=42),
        'DecisionTreeRegressor': DecisionTreeRegressor(random_state=42),
        'LinearRegression': LinearRegression()
    }
    model = model_map.get(model_name)
    if not model:
        print(f"Model {model_name} not found.")
        return pd.DataFrame()

    return pd.DataFrame(generate_predictions(data, kpi_columns, model))

# Process each BSO and model
ffc_data_random_forest = run_model_predictions("FFC Proj", "USFFC", "RandomForestRegressor", model_kpi_mapping["RandomForestRegressor"])
ffc_data_gradient_boosting = run_model_predictions("FFC Proj", "USFFC", "GradientBoostingRegressor", model_kpi_mapping["GradientBoostingRegressor"])
ffc_data_decision_tree = run_model_predictions("FFC Proj", "USFFC", "DecisionTreeRegressor", model_kpi_mapping["DecisionTreeRegressor"])
ffc_data_linear_regression = run_model_predictions("FFC Proj", "USFFC", "LinearRegression", model_kpi_mapping["LinearRegression"])

# Combine results for all models
all_predictions = pd.concat([ffc_data_random_forest, ffc_data_gradient_boosting, ffc_data_decision_tree, ffc_data_linear_regression], ignore_index=True)

# Show the final DataFrame
print(all_predictions)
