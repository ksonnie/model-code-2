import pandas as pd
import numpy as np
from sklearn.model_selection import train_test_split
from sklearn.linear_model import LinearRegression
from sklearn.ensemble import GradientBoostingRegressor
from xgboost import XGBRegressor

# File path and relevant BSO sheets
file_path = "/Volumes/navy-fip4-ya-dev/data_cleansing_dev/visualization_dev/All BSOs Dashboards.xlsx"
bso_sheets = {
    'USFFC': 'FFC Proj'
}

# Model Mapping Dictionary: BSO, KPI Column, and Best Model
model_mapping = {
    ('USFFC', 'NULOs that Remain High Priority'): 'XGBoost Regressor',
    ('USFFC', 'Billing exceeds Authorization (Abnormal Unfilled Customer Orders)'): 'XGBoost Regressor',
    ('USFFC', 'RBC Level- Total Negative Billed'): 'XGBoost Regressor',
    ('USFFC', 'RBC Level- Total Negative Authorizations'): 'Gradient Boosting',
}

# Function to replace NA with zeros
def replace_na_with_zeros(df):
    return df.fillna(0)

# Function to process BSO sheets and make predictions
def process_bso_sheets(file_path, bso_sheets, model_mapping):
    consolidated_data = []

    for (bso, kpi_column), best_model_name in model_mapping.items():
        print(f"Processing BSO: {bso}, KPI: {kpi_column}, Model: {best_model_name}")

        # Identify the corresponding sheet for this BSO
        if bso not in bso_sheets:
            print(f"BSO {bso} not found in bso_sheets. Skipping.")
            continue

        sheet_name = bso_sheets[bso]

        # Read the relevant sheet
        data = pd.read_excel(file_path, sheet_name=sheet_name)
        data = replace_na_with_zeros(data)

        # Ensure Date column is properly formatted
        if 'Date' in data.columns:
            data['Date'] = pd.to_datetime(data['Date'], errors='coerce')
            if data['Date'].isnull().any():
                print(f"Invalid dates found in sheet: {sheet_name}. Replacing with earliest valid date.")
                earliest_date = data['Date'].dropna().min()
                data['Date'].fillna(earliest_date, inplace=True)
        else:
            print(f"Date column missing in sheet {sheet_name}. Skipping...")
            continue

        last_date = data['Date'].max()
        print(f"Last historical date: {last_date}")

        # Prepare data for modeling
        if kpi_column not in data.columns:
            print(f"KPI column {kpi_column} not found in sheet {sheet_name}. Skipping.")
            continue

        data['DateNumeric'] = data['Date'].map(pd.Timestamp.toordinal)
        X = data[['DateNumeric']]
        y = data[kpi_column]

        if np.any(np.isnan(y)) or np.any(np.isinf(y)):
            print(f"Invalid values in KPI column {kpi_column}. Skipping...")
            continue

        # Model selection
        model = None
        if best_model_name == 'XGBoost Regressor':
            model = XGBRegressor(random_state=42)
        elif best_model_name == 'Gradient Boosting':
            model = GradientBoostingRegressor(random_state=42)
        elif best_model_name == 'Linear Regression':
            model = LinearRegression()
        else:
            print(f"Unknown Model: {best_model_name} for KPI: {kpi_column}. Skipping.")
            continue

        try:
            # Split and train the model
            X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)
            model.fit(X_train, y_train)
            print(f"Model trained successfully for {kpi_column}")

            # Generate predictions for the next 3 weeks
            future_predictions = []
            for i in range(3):
                next_date = last_date + pd.Timedelta(days=7)
                next_date_numeric = next_date.toordinal()
                prediction = model.predict([[next_date_numeric]])[0]

                print(f"Prediction for {next_date}: {prediction}")
                future_predictions.append({'Date': next_date, kpi_column: prediction})

                # Update historical data
                new_row = pd.DataFrame({'Date': [next_date], 'DateNumeric': [next_date_numeric], kpi_column: [prediction]})
                data = pd.concat([data, new_row], ignore_index=True)
                last_date = next_date

            # Append predictions to consolidated data
            consolidated_data.append(pd.DataFrame(future_predictions))

        except Exception as e:
            print(f"Error during prediction for {kpi_column}: {e}")
            continue

    # Combine all predictions into a single DataFrame
    if consolidated_data:
        consolidated_df = pd.concat(consolidated_data, ignore_index=True)
        return consolidated_df
    else:
        return pd.DataFrame()  # Return empty DataFrame if no predictions

# Process all BSO sheets and consolidate the results
consolidated_results = process_bso_sheets(file_path, bso_sheets, model_mapping)

# Display consolidated results
print(consolidated_results)
